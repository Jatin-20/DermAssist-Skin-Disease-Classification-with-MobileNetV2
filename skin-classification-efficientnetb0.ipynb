{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2529450,"sourceType":"datasetVersion","datasetId":1532614}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:47:06.244103Z","iopub.execute_input":"2024-07-04T06:47:06.244772Z","iopub.status.idle":"2024-07-04T06:47:20.677995Z","shell.execute_reply.started":"2024-07-04T06:47:06.244745Z","shell.execute_reply":"2024-07-04T06:47:20.676954Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-04 06:47:08.367382: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-04 06:47:08.367490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-04 06:47:08.552526: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom sklearn.model_selection import train_test_split\n\ndef split_dataset(source_dir, target_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n    # Create target directories\n    for split in ['train', 'val', 'test']:\n        split_dir = os.path.join(target_dir, split)\n        if not os.path.exists(split_dir):\n            os.makedirs(split_dir)\n\n    # Get all class folders\n    class_dirs = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n\n    for class_dir in class_dirs:\n        # Create class directories in train, val, and test\n        for split in ['train', 'val', 'test']:\n            class_split_dir = os.path.join(target_dir, split, class_dir)\n            if not os.path.exists(class_split_dir):\n                os.makedirs(class_split_dir)\n\n        # Get all images in the class\n        class_path = os.path.join(source_dir, class_dir)\n        images = [img for img in os.listdir(class_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n\n        # Split the data\n        train_val, test = train_test_split(images, test_size=test_ratio, random_state=42)\n        train, val = train_test_split(train_val, test_size=val_ratio/(train_ratio+val_ratio), random_state=42)\n\n        # Copy images to respective directories\n        for img in train:\n            shutil.copy(os.path.join(class_path, img), os.path.join(target_dir, 'train', class_dir, img))\n        for img in val:\n            shutil.copy(os.path.join(class_path, img), os.path.join(target_dir, 'val', class_dir, img))\n        for img in test:\n            shutil.copy(os.path.join(class_path, img), os.path.join(target_dir, 'test', class_dir, img))\n\n    print(\"Dataset split completed.\")\n\n# Usage\nsource_directory = '/kaggle/input/skin-diseases-image-dataset/IMG_CLASSES'\ntarget_directory = '/kaggle/working/'\n\nsplit_dataset(source_directory, target_directory)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:49:17.216923Z","iopub.execute_input":"2024-07-04T06:49:17.217303Z","iopub.status.idle":"2024-07-04T06:54:07.096516Z","shell.execute_reply.started":"2024-07-04T06:49:17.217272Z","shell.execute_reply":"2024-07-04T06:54:07.095607Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Dataset split completed.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Check for available GPUs and configure TensorFlow to use them\nphysical_devices = tf.config.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n    print(f\"Found {len(physical_devices)} GPU(s)\")\n    for device in physical_devices:\n        tf.config.experimental.set_memory_growth(device, True)\n    print(\"GPU is enabled\")\nelse:\n    print(\"No GPU found. Running on CPU\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:54:38.055317Z","iopub.execute_input":"2024-07-04T06:54:38.055669Z","iopub.status.idle":"2024-07-04T06:54:38.301947Z","shell.execute_reply.started":"2024-07-04T06:54:38.055641Z","shell.execute_reply":"2024-07-04T06:54:38.300927Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 2 GPU(s)\nGPU is enabled\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Set paths\nbase_dir = '/kaggle/working/dataset'\ntrain_dir = os.path.join(base_dir, 'train')\nval_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:54:41.839890Z","iopub.execute_input":"2024-07-04T06:54:41.840579Z","iopub.status.idle":"2024-07-04T06:54:41.845880Z","shell.execute_reply.started":"2024-07-04T06:54:41.840546Z","shell.execute_reply":"2024-07-04T06:54:41.844868Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n# ImageDataGenerator for data augmentation and rescaling\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    shear_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='reflect',\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)\n\nvalid_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\ntest_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:54:58.332897Z","iopub.execute_input":"2024-07-04T06:54:58.333485Z","iopub.status.idle":"2024-07-04T06:54:58.341265Z","shell.execute_reply.started":"2024-07-04T06:54:58.333443Z","shell.execute_reply":"2024-07-04T06:54:58.340175Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n\n# Load datasets\nbatch_size = 32\nimg_size = (224, 224)\ntrain_generator = train_datagen.flow_from_directory('/kaggle/working/train', target_size=img_size,\n                                                    batch_size=batch_size, class_mode='categorical')\nvalid_generator = valid_datagen.flow_from_directory('/kaggle/working/val', target_size=img_size,\n                                                    batch_size=batch_size, class_mode='categorical')\ntest_generator = test_datagen.flow_from_directory('/kaggle/working/test', target_size=img_size,\n                                                  batch_size=batch_size, class_mode='categorical', shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:57:51.275662Z","iopub.execute_input":"2024-07-04T06:57:51.276018Z","iopub.status.idle":"2024-07-04T06:57:52.214629Z","shell.execute_reply.started":"2024-07-04T06:57:51.275994Z","shell.execute_reply":"2024-07-04T06:57:52.213739Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 18997 images belonging to 10 classes.\nFound 4078 images belonging to 10 classes.\nFound 4078 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Function to create the model\ndef create_model():\n    base_model = EfficientNetB0(input_shape=(*img_size, 3), include_top=False, weights='imagenet')\n    base_model.trainable = False\n\n    model = Sequential([\n        base_model,\n        GlobalAveragePooling2D(),\n        Dropout(0.5),\n        Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n        Dropout(0.5),\n        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n        Dropout(0.3),\n        Dense(10, activation='softmax')\n    ])\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:58:06.415362Z","iopub.execute_input":"2024-07-04T06:58:06.416005Z","iopub.status.idle":"2024-07-04T06:58:06.422141Z","shell.execute_reply.started":"2024-07-04T06:58:06.415974Z","shell.execute_reply":"2024-07-04T06:58:06.421262Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n# Callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n\n# Training parameters\nepochs = 50\nn_splits = 5","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:58:16.457577Z","iopub.execute_input":"2024-07-04T06:58:16.458283Z","iopub.status.idle":"2024-07-04T06:58:16.462889Z","shell.execute_reply.started":"2024-07-04T06:58:16.458252Z","shell.execute_reply":"2024-07-04T06:58:16.462002Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n\n# K-fold Cross-validation\nkfold = KFold(n_splits=n_splits, shuffle=True)\ncv_scores = []\n\nfor fold, (train_index, val_index) in enumerate(kfold.split(train_generator.filenames)):\n    print(f\"Fold {fold+1}/{n_splits}\")\n    \n    model = create_model()\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:58:30.509794Z","iopub.execute_input":"2024-07-04T06:58:30.510683Z","iopub.status.idle":"2024-07-04T06:58:38.202349Z","shell.execute_reply.started":"2024-07-04T06:58:30.510649Z","shell.execute_reply":"2024-07-04T06:58:38.201553Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Fold 1/5\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nFold 2/5\nFold 3/5\nFold 4/5\nFold 5/5\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:35:15.827861Z","iopub.execute_input":"2024-07-04T07:35:15.828196Z","iopub.status.idle":"2024-07-04T07:35:15.835879Z","shell.execute_reply.started":"2024-07-04T07:35:15.828170Z","shell.execute_reply":"2024-07-04T07:35:15.834609Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[15], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    base_model = model.layers[0]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"],"ename":"IndentationError","evalue":"unexpected indent (2010335002.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"\n    # Train the model\n    history = model.fit(\n        train_generator,\n        steps_per_epoch=len(train_index) // batch_size,\n        epochs=epochs,\n        validation_data=valid_generator,\n        validation_steps=len(val_index) // batch_size,\n        callbacks=[early_stopping, reduce_lr]\n    )\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T06:58:48.836669Z","iopub.execute_input":"2024-07-04T06:58:48.837408Z","iopub.status.idle":"2024-07-04T07:30:20.446688Z","shell.execute_reply.started":"2024-07-04T06:58:48.837374Z","shell.execute_reply":"2024-07-04T07:30:20.445782Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/474\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.1016 - loss: 8.1917   ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1720076374.001502     183 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1720076374.059685     183 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m288/474\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 571ms/step - accuracy: 0.2831 - loss: 3.9898","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720076537.845674     183 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.2861 - loss: 3.4786","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720076632.973195     184 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 589ms/step - accuracy: 0.2861 - loss: 3.4767 - val_accuracy: 0.2934 - val_loss: 2.1488 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m120/474\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 442ms/step - accuracy: 0.2735 - loss: 2.1641","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 130ms/step - accuracy: 0.2875 - loss: 2.1496 - val_accuracy: 0.3179 - val_loss: 2.1158 - learning_rate: 0.0010\nEpoch 3/50\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720076713.750552     184 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 508ms/step - accuracy: 0.2916 - loss: 2.1408 - val_accuracy: 0.2990 - val_loss: 2.1220 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 114ms/step - accuracy: 0.2887 - loss: 2.1342 - val_accuracy: 0.2417 - val_loss: 2.1972 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 502ms/step - accuracy: 0.2898 - loss: 2.1382 - val_accuracy: 0.2953 - val_loss: 2.1274 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 111ms/step - accuracy: 0.2932 - loss: 2.1357 - val_accuracy: 0.2781 - val_loss: 2.1416 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 517ms/step - accuracy: 0.2953 - loss: 2.1273 - val_accuracy: 0.2945 - val_loss: 2.1272 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 112ms/step - accuracy: 0.2802 - loss: 2.1517 - val_accuracy: 0.2881 - val_loss: 2.1424 - learning_rate: 2.0000e-04\nEpoch 9/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 507ms/step - accuracy: 0.2957 - loss: 2.1275 - val_accuracy: 0.2926 - val_loss: 2.1278 - learning_rate: 2.0000e-04\nEpoch 10/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 112ms/step - accuracy: 0.2945 - loss: 2.1261 - val_accuracy: 0.2616 - val_loss: 2.1611 - learning_rate: 2.0000e-04\nEpoch 11/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 538ms/step - accuracy: 0.2956 - loss: 2.1266 - val_accuracy: 0.2889 - val_loss: 2.1332 - learning_rate: 2.0000e-04\nEpoch 12/50\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.3035 - loss: 2.1168 - val_accuracy: 0.2947 - val_loss: 2.1262 - learning_rate: 2.0000e-04\n","output_type":"stream"}]},{"cell_type":"code","source":"\n    # Evaluate the model\n    scores = model.evaluate(test_generator)\n    cv_scores.append(scores[1])\n    print(f\"Fold {fold+1} - Test accuracy: {scores[1]*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:34:16.106311Z","iopub.execute_input":"2024-07-04T07:34:16.107319Z","iopub.status.idle":"2024-07-04T07:34:38.168410Z","shell.execute_reply.started":"2024-07-04T07:34:16.107275Z","shell.execute_reply":"2024-07-04T07:34:38.167505Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 171ms/step - accuracy: 0.1707 - loss: 2.2658\nFold 5 - Test accuracy: 29.33%\n","output_type":"stream"}]},{"cell_type":"code","source":"\n    # Fine-tuning\n    base_model = model.layers[0]\n    base_model.trainable = True\n    for layer in base_model.layers[:-30]:\n        layer.trainable = False\n    \n    model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    history_fine = model.fit(\n        train_generator,\n        steps_per_epoch=len(train_index) // batch_size,\n        epochs=epochs // 2,  # Train for fewer epochs during fine-tuning\n        validation_data=valid_generator,\n        validation_steps=len(val_index) // batch_size,\n        callbacks=[early_stopping, reduce_lr]\n    )\n    \n   ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T07:39:08.316747Z","iopub.execute_input":"2024-07-04T07:39:08.317116Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/25\n\u001b[1m  2/474\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 63ms/step - accuracy: 0.2734 - loss: 2.1740   ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720078796.582608     186 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - accuracy: 0.2892 - loss: 2.1501","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720079024.644946     184 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 522ms/step - accuracy: 0.2892 - loss: 2.1501 - val_accuracy: 0.2921 - val_loss: 2.1381 - learning_rate: 1.0000e-05\nEpoch 2/25\n\u001b[1m 45/474\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:31\u001b[0m 1s/step - accuracy: 0.3029 - loss: 2.1261 ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720079089.767981     184 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 174ms/step - accuracy: 0.2914 - loss: 2.1461 - val_accuracy: 0.2517 - val_loss: 2.1894 - learning_rate: 1.0000e-05\nEpoch 3/25\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720079125.698972     183 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 504ms/step - accuracy: 0.2857 - loss: 2.1452 - val_accuracy: 0.2924 - val_loss: 2.1381 - learning_rate: 1.0000e-05\nEpoch 4/25\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 112ms/step - accuracy: 0.2909 - loss: 2.1420 - val_accuracy: 0.2947 - val_loss: 2.1099 - learning_rate: 1.0000e-05\nEpoch 5/25\n\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 504ms/step - accuracy: 0.2901 - loss: 2.1461 - val_accuracy: 0.2934 - val_loss: 2.1369 - learning_rate: 1.0000e-05\nEpoch 6/25\n\u001b[1m 12/474\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:22\u001b[0m 439ms/step - accuracy: 0.2711 - loss: 2.1595","output_type":"stream"}]},{"cell_type":"code","source":"\n    \n    # Plot training & validation accuracy and loss\n    plt.figure(figsize=(14, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title(f'Fold {fold+1} - Training and Validation Accuracy')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title(f'Fold {fold+1} - Training and Validation Loss')\n    plt.show()\n\n   \n    \n    # Evaluate after fine-tuning\n    scores_fine = model.evaluate(test_generator)\n    print(f\"Fold {fold+1} (after fine-tuning) - Test accuracy: {scores_fine[1]*100:.2f}%\")\n    \n    # Plot fine-tuning results\n    plt.figure(figsize=(14, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(history_fine.history['accuracy'], label='Training Accuracy')\n    plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title(f'Fold {fold+1} (Fine-tuning) - Training and Validation Accuracy')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history_fine.history['loss'], label='Training Loss')\n    plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title(f'Fold {fold+1} (Fine-tuning) - Training and Validation Loss')\n    plt.show()\n\nprint(f\"Average CV accuracy: {np.mean(cv_scores)*100:.2f}% (+/- {np.std(cv_scores)*100:.2f}%)\")","metadata":{},"execution_count":null,"outputs":[]}]}